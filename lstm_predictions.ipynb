{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T08:40:37.914230Z",
     "start_time": "2019-12-09T08:40:34.958540Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T08:40:37.926039Z",
     "start_time": "2019-12-09T08:40:37.915067Z"
    }
   },
   "outputs": [],
   "source": [
    "def fix_size(element, x_axis_size):\n",
    "    \"\"\"\n",
    "    Funkcja zwraca listę elementów o wymiarze x równym x_axis_size, a wymiarze y wziętym z argumentu element.\n",
    "    Jeśli element jest zbyt krótki to wydłużamy,\n",
    "    jeśli zbyt długi to kroimy na kawałki (być może ostatni będzie wydłużony),\n",
    "    jeśli jest ok to zostawiamy.\n",
    "    \"\"\"\n",
    "    if element.shape[0] < x_axis_size:\n",
    "        padding_size = (x_axis_size - element.shape[0], element.shape[1])\n",
    "        padding = np.zeros(padding_size)\n",
    "        return [np.concatenate((padding, element))]\n",
    "    \n",
    "    elif element.shape[0] > x_axis_size:\n",
    "        res = []\n",
    "        i = 0\n",
    "        while True:\n",
    "            res += fix_size(element[x_axis_size*i:x_axis_size*(i+1)], x_axis_size)\n",
    "            i += 1\n",
    "            if x_axis_size*i >= element.shape[0]:\n",
    "                break\n",
    "        return res\n",
    "    return [element]\n",
    "\n",
    "\n",
    "def batch_generator(file_name, batch_size=64, x_axis_size=20, reshape_y=False):\n",
    "    \"\"\"\n",
    "    Batche tworzone przez generator są wymiaru (batch_size, x_axis_size, długość wektora embeddingu).\n",
    "    \n",
    "    file_name: Ścieżka do pickle'a\n",
    "    batch_size: liczba rekordów w batchu\n",
    "    x_axis_size: wymiar \"x\" (otoczenia) każdego wystąpienia\n",
    "    reshape_y: flaga czy zwracany y powinien być wymiaru (n,) (False) czy (n, 1) (True)\n",
    "    \"\"\"\n",
    "    with open(file_name, 'rb') as f:\n",
    "        pickle_data = pickle.load(f)\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "    for label in pickle_data:\n",
    "        for el in pickle_data[label]:\n",
    "            curr_data = fix_size(el, x_axis_size)\n",
    "            data += curr_data\n",
    "            labels += [label] * len(curr_data)\n",
    "            \n",
    "    data = np.asarray(data)\n",
    "    labels = np.asarray(labels)\n",
    "    if reshape_y:\n",
    "        labels = labels.reshape(-1, 1)\n",
    "         \n",
    "    i = 0\n",
    "    while True:\n",
    "        yield data[batch_size*i:batch_size*(i+1), :, :], labels[batch_size*i:batch_size*(i+1)]\n",
    "        i += 1\n",
    "        if batch_size*i >= data.shape[0]:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T08:40:37.937022Z",
     "start_time": "2019-12-09T08:40:37.928045Z"
    }
   },
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    'politycy': 0,\n",
    "    'dziennikarze': 1,\n",
    "    'duchowni': 2,\n",
    "    'aktorzy': 3,\n",
    "    'lekarze': 4,\n",
    "    'malarze': 5,\n",
    "    'muzycy': 6,\n",
    "    'poeci': 7,\n",
    "    'prawnicy': 8,\n",
    "    'sportowcy': 9\n",
    "}\n",
    "\n",
    "\n",
    "class EmbedDataset(Dataset):\n",
    "    def __init__(self, file_name, mapping, x_axis_size=20, reshape_y=False):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            pickle_data = pickle.load(f)\n",
    "        data = []\n",
    "        labels = []\n",
    "        for label in pickle_data:\n",
    "            for el in pickle_data[label]:\n",
    "                curr_data = fix_size(el, x_axis_size)\n",
    "                data += curr_data\n",
    "                labels += [label] * len(curr_data)\n",
    "        self.data = np.asarray(data)\n",
    "        self.mapping = mapping\n",
    "        self.inverse_mapping = {v: k for k,v in self.mapping.items()}\n",
    "        self.labels = np.asarray([self.mapping[l] for l in labels])\n",
    "#         if reshape_y:\n",
    "#             self.labels = self.labels.reshape(-1, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T08:40:38.779248Z",
     "start_time": "2019-12-09T08:40:37.939012Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_classes = 10\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T08:40:38.788055Z",
     "start_time": "2019-12-09T08:40:38.780076Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim, unique_classes, seq_len, embeding_dim):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.embeding_dim = embeding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.embeding_dim, self.hidden_dim, batch_first = True)\n",
    "        # self.linear = nn.Linear(hidden_dim * seq_len, unique_classes)\n",
    "        self.linear = nn.Linear(hidden_dim, unique_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _ , _ = x.shape\n",
    "        # lstm_out, _ = self.lstm(x.view(self.seq_len, batch_size, -1))\n",
    "        # outputs = self.linear(lstm_out.reshape(batch_size, -1))\n",
    "        _, (final_hidden_state, _) = self.lstm(x) #, (h_0, c_0))\n",
    "        outputs = self.linear(final_hidden_state.view(batch_size, -1))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T08:40:38.805016Z",
     "start_time": "2019-12-09T08:40:38.790051Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_result_all_xd(model, optimizer, loss, provider_train, provider_test, provider_validation, device):\n",
    "    val_ba = []\n",
    "    val_prec = []\n",
    "    val_rec = []\n",
    "    val_f1 = []\n",
    "    val_matth = []\n",
    "\n",
    "    for epoch in range(20):\n",
    "        train_start_time = time.time()\n",
    "        for i, (X_batch, y_batch) in enumerate(provider_train):\n",
    "            X_batch = X_batch.long().to(device)\n",
    "            y_batch = y_batch.long().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            target_preds = model(X_batch)\n",
    "            loss = torch.nn.functional.cross_entropy(target_preds, y_batch)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        true_values = np.array([])\n",
    "        pred_values = np.array([])\n",
    "        for i, (X_batch, y_batch) in enumerate(provider_validation):\n",
    "            X_batch = X_batch.long().to(device)\n",
    "            y_batch = y_batch.long().to(device)\n",
    "\n",
    "            pred_values = np.append(pred_values, model(X_batch).argmax(dim = 1).cpu().numpy())\n",
    "            true_values = np.append(true_values, y_batch.cpu().numpy())\n",
    "        val_ba.append(balanced_accuracy_score(true_values, pred_values, adjusted=False))\n",
    "        val_prec.append(precision_score(true_values, pred_values, average = 'weighted'))\n",
    "        val_rec.append(recall_score(true_values, pred_values, average = 'weighted'))\n",
    "        val_f1.append(f1_score(true_values, pred_values, average = 'weighted'))\n",
    "        val_matth.append(matthews_corrcoef(true_values, pred_values))\n",
    "        print('| Epoch: {:3d} | Time: {:6.2f}s | Balanced Acc: {:5.2f} | Prec: {:5.2f} | Recall: {:5.2f} | F1: {:5.2f} | Matthews: {:5.2f} |'\n",
    "                      .format(epoch+1, (time.time() - train_start_time), val_ba[epoch], val_prec[epoch], val_rec[epoch], val_f1[epoch], val_matth[epoch]))\n",
    "\n",
    "    test_ba = []\n",
    "    test_prec = []\n",
    "    test_rec = []\n",
    "    test_f1 = []\n",
    "    test_matth = []\n",
    "    true_values = np.array([])\n",
    "    pred_values = np.array([])\n",
    "    for i, (X_batch, y_batch) in enumerate(provider_test):\n",
    "        X_batch = X_batch.long().to(device)\n",
    "        y_batch = y_batch.long().to(device)\n",
    "\n",
    "        pred_values = np.append(pred_values, model(X_batch).argmax(dim = 1).cpu().numpy())\n",
    "        true_values = np.append(true_values, y_batch.cpu().numpy())\n",
    "\n",
    "    test_ba = balanced_accuracy_score(true_values, pred_values, adjusted=False)\n",
    "    test_prec = precision_score(true_values, pred_values, average = 'weighted')\n",
    "    test_rec = recall_score(true_values, pred_values, average = 'weighted')\n",
    "    test_f1 = f1_score(true_values, pred_values, average = 'weighted')\n",
    "    test_matth = matthews_corrcoef(true_values, pred_values)\n",
    "    print('| TEST SET | Balanced Acc: {:5.2f} | Prec: {:5.2f} | Recall: {:5.2f} | F1: {:5.2f} | Matthews: {:5.2f} |'\n",
    "                      .format(test_ba, test_prec, test_rec, test_f1, test_matth))\n",
    "    \n",
    "    return test_ba, test_prec, test_rec, test_f1, test_matth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T16:22:56.982721Z",
     "start_time": "2019-11-30T16:22:56.978803Z"
    }
   },
   "outputs": [],
   "source": [
    "embeding_dim = 768\n",
    "seq_len = 32\n",
    "hidden_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T16:22:57.283447Z",
     "start_time": "2019-11-30T16:22:57.279489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T16:23:31.120785Z",
     "start_time": "2019-11-30T16:22:57.795111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch:   1 | Time:   1.47s | Balanced Acc:  0.10 | Prec:  0.32 | Recall:  0.57 | F1:  0.41 | Matthews:  0.00 |\n",
      "| Epoch:   2 | Time:   1.27s | Balanced Acc:  0.10 | Prec:  0.32 | Recall:  0.57 | F1:  0.41 | Matthews:  0.00 |\n",
      "| Epoch:   3 | Time:   0.94s | Balanced Acc:  0.10 | Prec:  0.38 | Recall:  0.57 | F1:  0.42 | Matthews:  0.03 |\n",
      "| Epoch:   4 | Time:   1.19s | Balanced Acc:  0.16 | Prec:  0.50 | Recall:  0.61 | F1:  0.53 | Matthews:  0.27 |\n",
      "| Epoch:   5 | Time:   1.34s | Balanced Acc:  0.16 | Prec:  0.49 | Recall:  0.61 | F1:  0.52 | Matthews:  0.26 |\n",
      "| Epoch:   6 | Time:   1.19s | Balanced Acc:  0.16 | Prec:  0.51 | Recall:  0.61 | F1:  0.51 | Matthews:  0.27 |\n",
      "| Epoch:   7 | Time:   1.17s | Balanced Acc:  0.17 | Prec:  0.49 | Recall:  0.60 | F1:  0.52 | Matthews:  0.25 |\n",
      "| Epoch:   8 | Time:   1.17s | Balanced Acc:  0.21 | Prec:  0.49 | Recall:  0.60 | F1:  0.51 | Matthews:  0.24 |\n",
      "| Epoch:   9 | Time:   1.21s | Balanced Acc:  0.22 | Prec:  0.52 | Recall:  0.62 | F1:  0.54 | Matthews:  0.29 |\n",
      "| Epoch:  10 | Time:   1.52s | Balanced Acc:  0.17 | Prec:  0.49 | Recall:  0.61 | F1:  0.53 | Matthews:  0.27 |\n",
      "| Epoch:  11 | Time:   2.42s | Balanced Acc:  0.23 | Prec:  0.51 | Recall:  0.61 | F1:  0.54 | Matthews:  0.28 |\n",
      "| Epoch:  12 | Time:   1.64s | Balanced Acc:  0.29 | Prec:  0.53 | Recall:  0.61 | F1:  0.55 | Matthews:  0.30 |\n",
      "| Epoch:  13 | Time:   2.11s | Balanced Acc:  0.25 | Prec:  0.53 | Recall:  0.60 | F1:  0.55 | Matthews:  0.29 |\n",
      "| Epoch:  14 | Time:   2.14s | Balanced Acc:  0.26 | Prec:  0.54 | Recall:  0.61 | F1:  0.56 | Matthews:  0.30 |\n",
      "| Epoch:  15 | Time:   2.18s | Balanced Acc:  0.25 | Prec:  0.54 | Recall:  0.61 | F1:  0.55 | Matthews:  0.29 |\n",
      "| Epoch:  16 | Time:   2.21s | Balanced Acc:  0.31 | Prec:  0.55 | Recall:  0.59 | F1:  0.56 | Matthews:  0.30 |\n",
      "| Epoch:  17 | Time:   1.71s | Balanced Acc:  0.28 | Prec:  0.52 | Recall:  0.59 | F1:  0.53 | Matthews:  0.25 |\n",
      "| Epoch:  18 | Time:   2.19s | Balanced Acc:  0.31 | Prec:  0.56 | Recall:  0.62 | F1:  0.57 | Matthews:  0.32 |\n",
      "| Epoch:  19 | Time:   1.59s | Balanced Acc:  0.23 | Prec:  0.56 | Recall:  0.60 | F1:  0.53 | Matthews:  0.26 |\n",
      "| Epoch:  20 | Time:   1.35s | Balanced Acc:  0.30 | Prec:  0.54 | Recall:  0.60 | F1:  0.56 | Matthews:  0.31 |\n",
      "| TEST SET | Balanced Acc:  0.22 | Prec:  0.56 | Recall:  0.60 | F1:  0.57 | Matthews:  0.28 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.217920061560746,\n",
       " 0.5578550636863685,\n",
       " 0.6009389671361502,\n",
       " 0.5743093388299376,\n",
       " 0.27992581357414636)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM(embeding_dim=embeding_dim, hidden_dim=hidden_dim, unique_classes=unique_classes, seq_len=seq_len).to(device)\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=1e-3)\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits\n",
    "\n",
    "\n",
    "bert_gazeta_train_path = './embeddings/BERT/GAZETA_train.pickle'\n",
    "bert_gazeta_test_path = './embeddings/BERT/GAZETA_test.pickle'\n",
    "bert_gazeta_validation_path = './embeddings/BERT/GAZETA_validation.pickle'\n",
    "\n",
    "data = EmbedDataset(bert_gazeta_train_path, class_mapping)\n",
    "provider_train = DataLoader(data, batch_size=64, shuffle=True)\n",
    "\n",
    "data = EmbedDataset(bert_gazeta_test_path, class_mapping)\n",
    "provider_test = DataLoader(data, batch_size=64, shuffle=False)\n",
    "\n",
    "data = EmbedDataset(bert_gazeta_validation_path, class_mapping)\n",
    "provider_validation = DataLoader(data, batch_size=64, shuffle=False)\n",
    "\n",
    "train_result_all_xd(model, optimizer, loss, provider_train, provider_test, provider_validation, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T16:24:46.300534Z",
     "start_time": "2019-11-30T16:23:55.795044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch:   1 | Time:   2.89s | Balanced Acc:  0.10 | Prec:  0.53 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:   2 | Time:   2.72s | Balanced Acc:  0.10 | Prec:  0.53 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:   3 | Time:   3.49s | Balanced Acc:  0.10 | Prec:  0.53 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:   4 | Time:   2.35s | Balanced Acc:  0.13 | Prec:  0.59 | Recall:  0.74 | F1:  0.64 | Matthews:  0.16 |\n",
      "| Epoch:   5 | Time:   2.13s | Balanced Acc:  0.13 | Prec:  0.58 | Recall:  0.73 | F1:  0.64 | Matthews:  0.14 |\n",
      "| Epoch:   6 | Time:   1.87s | Balanced Acc:  0.21 | Prec:  0.60 | Recall:  0.73 | F1:  0.65 | Matthews:  0.20 |\n",
      "| Epoch:   7 | Time:   2.46s | Balanced Acc:  0.18 | Prec:  0.61 | Recall:  0.74 | F1:  0.66 | Matthews:  0.23 |\n",
      "| Epoch:   8 | Time:   2.58s | Balanced Acc:  0.16 | Prec:  0.60 | Recall:  0.72 | F1:  0.65 | Matthews:  0.17 |\n",
      "| Epoch:   9 | Time:   2.21s | Balanced Acc:  0.16 | Prec:  0.59 | Recall:  0.72 | F1:  0.64 | Matthews:  0.17 |\n",
      "| Epoch:  10 | Time:   2.42s | Balanced Acc:  0.13 | Prec:  0.58 | Recall:  0.72 | F1:  0.64 | Matthews:  0.13 |\n",
      "| Epoch:  11 | Time:   3.32s | Balanced Acc:  0.16 | Prec:  0.63 | Recall:  0.70 | F1:  0.64 | Matthews:  0.15 |\n",
      "| Epoch:  12 | Time:   2.90s | Balanced Acc:  0.15 | Prec:  0.63 | Recall:  0.72 | F1:  0.65 | Matthews:  0.15 |\n",
      "| Epoch:  13 | Time:   3.01s | Balanced Acc:  0.14 | Prec:  0.59 | Recall:  0.72 | F1:  0.64 | Matthews:  0.13 |\n",
      "| Epoch:  14 | Time:   2.54s | Balanced Acc:  0.17 | Prec:  0.63 | Recall:  0.70 | F1:  0.64 | Matthews:  0.15 |\n",
      "| Epoch:  15 | Time:   2.56s | Balanced Acc:  0.13 | Prec:  0.58 | Recall:  0.69 | F1:  0.62 | Matthews:  0.08 |\n",
      "| Epoch:  16 | Time:   2.07s | Balanced Acc:  0.23 | Prec:  0.62 | Recall:  0.62 | F1:  0.61 | Matthews:  0.13 |\n",
      "| Epoch:  17 | Time:   2.02s | Balanced Acc:  0.16 | Prec:  0.60 | Recall:  0.69 | F1:  0.63 | Matthews:  0.12 |\n",
      "| Epoch:  18 | Time:   1.66s | Balanced Acc:  0.21 | Prec:  0.62 | Recall:  0.64 | F1:  0.63 | Matthews:  0.14 |\n",
      "| Epoch:  19 | Time:   1.81s | Balanced Acc:  0.17 | Prec:  0.62 | Recall:  0.68 | F1:  0.65 | Matthews:  0.17 |\n",
      "| Epoch:  20 | Time:   2.01s | Balanced Acc:  0.16 | Prec:  0.60 | Recall:  0.71 | F1:  0.64 | Matthews:  0.14 |\n",
      "| TEST SET | Balanced Acc:  0.24 | Prec:  0.59 | Recall:  0.68 | F1:  0.61 | Matthews:  0.19 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2404132760833132,\n",
       " 0.5925585658863395,\n",
       " 0.6828793774319066,\n",
       " 0.6108894707642167,\n",
       " 0.1909797456107152)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM(embeding_dim=embeding_dim, hidden_dim=hidden_dim, unique_classes=unique_classes, seq_len=seq_len).to(device)\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=1e-3)\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits\n",
    "\n",
    "bert_gazeta_train_path = './embeddings/BERT/ONET_train.pickle'\n",
    "bert_gazeta_test_path = './embeddings/BERT/ONET_test.pickle'\n",
    "bert_gazeta_validation_path = './embeddings/BERT/ONET_validation.pickle'\n",
    "\n",
    "data = EmbedDataset(bert_gazeta_train_path, class_mapping)\n",
    "provider_train = DataLoader(data, batch_size=64, shuffle=True)\n",
    "\n",
    "data = EmbedDataset(bert_gazeta_test_path, class_mapping)\n",
    "provider_test = DataLoader(data, batch_size=64, shuffle=False)\n",
    "\n",
    "data = EmbedDataset(bert_gazeta_validation_path, class_mapping)\n",
    "provider_validation = DataLoader(data, batch_size=64, shuffle=False)\n",
    "\n",
    "train_result_all_xd(model, optimizer, loss, provider_train, provider_test, provider_validation, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T16:24:57.726973Z",
     "start_time": "2019-11-30T16:24:57.722987Z"
    }
   },
   "outputs": [],
   "source": [
    "embeding_dim = 4\n",
    "seq_len = 32\n",
    "hidden_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T16:25:23.605627Z",
     "start_time": "2019-11-30T16:24:58.098082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch:   1 | Time:   0.96s | Balanced Acc:  0.10 | Prec:  0.35 | Recall:  0.59 | F1:  0.44 | Matthews:  0.00 |\n",
      "| Epoch:   2 | Time:   1.12s | Balanced Acc:  0.10 | Prec:  0.35 | Recall:  0.59 | F1:  0.44 | Matthews:  0.00 |\n",
      "| Epoch:   3 | Time:   1.03s | Balanced Acc:  0.10 | Prec:  0.35 | Recall:  0.59 | F1:  0.44 | Matthews:  0.00 |\n",
      "| Epoch:   4 | Time:   0.98s | Balanced Acc:  0.10 | Prec:  0.35 | Recall:  0.59 | F1:  0.44 | Matthews:  0.00 |\n",
      "| Epoch:   5 | Time:   1.03s | Balanced Acc:  0.10 | Prec:  0.35 | Recall:  0.59 | F1:  0.44 | Matthews:  0.00 |\n",
      "| Epoch:   6 | Time:   1.09s | Balanced Acc:  0.10 | Prec:  0.35 | Recall:  0.59 | F1:  0.44 | Matthews:  0.00 |\n",
      "| Epoch:   7 | Time:   1.08s | Balanced Acc:  0.10 | Prec:  0.35 | Recall:  0.59 | F1:  0.44 | Matthews:  0.00 |\n",
      "| Epoch:   8 | Time:   1.39s | Balanced Acc:  0.10 | Prec:  0.35 | Recall:  0.59 | F1:  0.44 | Matthews:  0.00 |\n",
      "| Epoch:   9 | Time:   1.39s | Balanced Acc:  0.10 | Prec:  0.35 | Recall:  0.59 | F1:  0.44 | Matthews:  0.00 |\n",
      "| Epoch:  10 | Time:   0.98s | Balanced Acc:  0.10 | Prec:  0.35 | Recall:  0.59 | F1:  0.44 | Matthews:  0.00 |\n",
      "| Epoch:  11 | Time:   0.99s | Balanced Acc:  0.10 | Prec:  0.35 | Recall:  0.59 | F1:  0.44 | Matthews:  0.00 |\n",
      "| Epoch:  12 | Time:   1.61s | Balanced Acc:  0.10 | Prec:  0.35 | Recall:  0.59 | F1:  0.44 | Matthews:  0.00 |\n",
      "| Epoch:  13 | Time:   1.36s | Balanced Acc:  0.10 | Prec:  0.35 | Recall:  0.59 | F1:  0.44 | Matthews:  0.00 |\n",
      "| Epoch:  14 | Time:   1.44s | Balanced Acc:  0.10 | Prec:  0.35 | Recall:  0.59 | F1:  0.44 | Matthews:  0.00 |\n",
      "| Epoch:  15 | Time:   1.73s | Balanced Acc:  0.10 | Prec:  0.35 | Recall:  0.59 | F1:  0.44 | Matthews:  0.00 |\n",
      "| Epoch:  16 | Time:   1.47s | Balanced Acc:  0.10 | Prec:  0.35 | Recall:  0.59 | F1:  0.44 | Matthews:  0.00 |\n",
      "| Epoch:  17 | Time:   1.52s | Balanced Acc:  0.10 | Prec:  0.35 | Recall:  0.59 | F1:  0.44 | Matthews:  0.00 |\n",
      "| Epoch:  18 | Time:   1.30s | Balanced Acc:  0.10 | Prec:  0.35 | Recall:  0.59 | F1:  0.44 | Matthews:  0.00 |\n",
      "| Epoch:  19 | Time:   1.34s | Balanced Acc:  0.10 | Prec:  0.35 | Recall:  0.59 | F1:  0.44 | Matthews:  0.00 |\n",
      "| Epoch:  20 | Time:   1.42s | Balanced Acc:  0.10 | Prec:  0.35 | Recall:  0.59 | F1:  0.44 | Matthews:  0.00 |\n",
      "| TEST SET | Balanced Acc:  0.10 | Prec:  0.42 | Recall:  0.65 | F1:  0.51 | Matthews:  0.00 |\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-bbf66a96971d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprovider_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_result_all_xd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprovider_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprovider_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprovider_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "model = LSTM(embeding_dim=embeding_dim, hidden_dim=hidden_dim, unique_classes=unique_classes, seq_len=seq_len).to(device)\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=1e-3)\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits\n",
    "\n",
    "\n",
    "bert_gazeta_train_path = './embeddings/random/GAZETA_train.pickle'\n",
    "bert_gazeta_test_path = './embeddings/random/GAZETA_test.pickle'\n",
    "bert_gazeta_validation_path = './embeddings/random/GAZETA_validation.pickle'\n",
    "\n",
    "data = EmbedDataset(bert_gazeta_train_path, class_mapping)\n",
    "provider_train = DataLoader(data, batch_size=64, shuffle=True)\n",
    "\n",
    "data = EmbedDataset(bert_gazeta_test_path, class_mapping)\n",
    "provider_test = DataLoader(data, batch_size=64, shuffle=False)\n",
    "\n",
    "data = EmbedDataset(bert_gazeta_validation_path, class_mapping)\n",
    "provider_validation = DataLoader(data, batch_size=64, shuffle=False)\n",
    "\n",
    "x,y = train_result_all_xd(model, optimizer, loss, provider_train, provider_test, provider_validation, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T16:26:05.094119Z",
     "start_time": "2019-11-30T16:25:27.921844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch:   1 | Time:   1.76s | Balanced Acc:  0.10 | Prec:  0.54 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:   2 | Time:   1.62s | Balanced Acc:  0.10 | Prec:  0.54 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:   3 | Time:   1.50s | Balanced Acc:  0.10 | Prec:  0.54 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:   4 | Time:   1.77s | Balanced Acc:  0.10 | Prec:  0.54 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:   5 | Time:   1.58s | Balanced Acc:  0.10 | Prec:  0.54 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:   6 | Time:   1.69s | Balanced Acc:  0.10 | Prec:  0.54 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:   7 | Time:   1.65s | Balanced Acc:  0.10 | Prec:  0.54 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:   8 | Time:   2.39s | Balanced Acc:  0.10 | Prec:  0.54 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:   9 | Time:   1.63s | Balanced Acc:  0.10 | Prec:  0.54 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:  10 | Time:   2.68s | Balanced Acc:  0.10 | Prec:  0.54 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:  11 | Time:   2.52s | Balanced Acc:  0.10 | Prec:  0.54 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:  12 | Time:   2.22s | Balanced Acc:  0.10 | Prec:  0.54 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:  13 | Time:   1.63s | Balanced Acc:  0.10 | Prec:  0.54 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:  14 | Time:   1.63s | Balanced Acc:  0.10 | Prec:  0.54 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:  15 | Time:   1.68s | Balanced Acc:  0.10 | Prec:  0.54 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:  16 | Time:   1.52s | Balanced Acc:  0.10 | Prec:  0.54 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:  17 | Time:   1.87s | Balanced Acc:  0.10 | Prec:  0.54 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:  18 | Time:   2.24s | Balanced Acc:  0.10 | Prec:  0.54 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:  19 | Time:   2.07s | Balanced Acc:  0.10 | Prec:  0.54 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| Epoch:  20 | Time:   1.31s | Balanced Acc:  0.10 | Prec:  0.54 | Recall:  0.73 | F1:  0.62 | Matthews:  0.00 |\n",
      "| TEST SET | Balanced Acc:  0.11 | Prec:  0.45 | Recall:  0.67 | F1:  0.54 | Matthews:  0.00 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1111111111111111,\n",
       " 0.4496360752046644,\n",
       " 0.670549084858569,\n",
       " 0.5383093250956242,\n",
       " 0.0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM(embeding_dim=embeding_dim, hidden_dim=hidden_dim, unique_classes=unique_classes, seq_len=seq_len).to(device)\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=1e-3)\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits\n",
    "\n",
    "bert_gazeta_train_path = './embeddings/random/ONET_train.pickle'\n",
    "bert_gazeta_test_path = './embeddings/random/ONET_test.pickle'\n",
    "bert_gazeta_validation_path = './embeddings/random/ONET_validation.pickle'\n",
    "\n",
    "data = EmbedDataset(bert_gafzeta_train_path, class_mapping)\n",
    "provider_train = DataLoader(data, batch_size=64, shuffle=True)\n",
    "\n",
    "data = EmbedDataset(bert_gazeta_test_path, class_mapping)\n",
    "provider_test = DataLoader(data, batch_size=64, shuffle=False)\n",
    "\n",
    "data = EmbedDataset(bert_gazeta_validation_path, class_mapping)\n",
    "provider_validation = DataLoader(data, batch_size=64, shuffle=False)\n",
    "\n",
    "train_result_all_xd(model, optimizer, loss, provider_train, provider_test, provider_validation, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words\n",
    "## GAZETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T08:40:49.953304Z",
     "start_time": "2019-12-09T08:40:49.892292Z"
    }
   },
   "outputs": [],
   "source": [
    "def open_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        pickle_data = pickle.load(f)\n",
    "    return pickle_data\n",
    "train = list(open_pickle('./embeddings/words/GAZETA_train.pickle').values())\n",
    "test = list(open_pickle('./embeddings/words/GAZETA_test.pickle').values())\n",
    "validation = list(open_pickle('./embeddings/words/GAZETA_validation.pickle').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T08:40:53.010945Z",
     "start_time": "2019-12-09T08:40:50.480641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28564"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = set()\n",
    "for i in train:\n",
    "    for j in i:\n",
    "            words = words.union(j)\n",
    "for i in test:\n",
    "    for j in i:\n",
    "            words = words.union(j)\n",
    "for i in validation:\n",
    "    for j in i:\n",
    "            words = words.union(j)\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T08:40:53.095718Z",
     "start_time": "2019-12-09T08:40:53.011910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4834, 17029, 22047, ...,  9605,  7812, 10669], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(list(words))\n",
    "le.transform(list(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T08:40:53.103698Z",
     "start_time": "2019-12-09T08:40:53.096684Z"
    }
   },
   "outputs": [],
   "source": [
    "class EmbedDatasetWords(Dataset):\n",
    "    def __init__(self, pickle_data, mapping, x_axis_size=20, reshape_y=False):\n",
    "        data = []\n",
    "        labels = []\n",
    "        for label in pickle_data:\n",
    "            for el in pickle_data[label]:\n",
    "                curr_data = fix_size(el, x_axis_size)\n",
    "                data += curr_data\n",
    "                labels += [label] * len(curr_data)\n",
    "        \n",
    "        self.data = np.asarray(data).reshape(len(data), x_axis_size)\n",
    "        self.mapping = mapping\n",
    "        self.inverse_mapping = {v: k for k,v in self.mapping.items()}\n",
    "        self.labels = np.asarray([self.mapping[l] for l in labels])\n",
    "#         if reshape_y:\n",
    "#             self.labels = self.labels.reshape(-1, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T08:41:29.605273Z",
     "start_time": "2019-12-09T08:40:53.105669Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./embeddings/words/GAZETA_train.pickle', 'rb') as f:\n",
    "    pickle_data = pickle.load(f)\n",
    "\n",
    "train_data = {k: list() for k in pickle_data}\n",
    "for label in pickle_data:\n",
    "    for el in pickle_data[label]:\n",
    "        converted = []\n",
    "        converted = le.transform(el)\n",
    "        train_data[label].append(np.array(converted).reshape(len(converted), 1))\n",
    "        \n",
    "data = EmbedDatasetWords(train_data, class_mapping)\n",
    "provider_train = DataLoader(data, batch_size=64, shuffle=True)\n",
    "\n",
    "with open('./embeddings/words/GAZETA_test.pickle', 'rb') as f:\n",
    "    pickle_data = pickle.load(f)\n",
    "    \n",
    "test_data = {k: list() for k in pickle_data}\n",
    "for label in pickle_data:\n",
    "    for el in pickle_data[label]:\n",
    "        converted = []\n",
    "        converted = le.transform(el)\n",
    "        test_data[label].append(np.array(converted).reshape(len(converted), 1))\n",
    "        \n",
    "data = EmbedDatasetWords(test_data, class_mapping)\n",
    "provider_test = DataLoader(data, batch_size=64, shuffle=True)\n",
    "\n",
    "with open('./embeddings/words/GAZETA_validation.pickle', 'rb') as f:\n",
    "    pickle_data = pickle.load(f)\n",
    "    \n",
    "val_data = {k: list() for k in pickle_data}\n",
    "for label in pickle_data:\n",
    "    for el in pickle_data[label]:\n",
    "        converted = []\n",
    "        converted = le.transform(el)\n",
    "        val_data[label].append(np.array(converted).reshape(len(converted), 1))\n",
    "        \n",
    "data = EmbedDatasetWords(val_data, class_mapping)\n",
    "provider_val = DataLoader(data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T08:55:58.094755Z",
     "start_time": "2019-12-09T08:55:58.089753Z"
    }
   },
   "outputs": [],
   "source": [
    "embeding_dim = 700\n",
    "seq_len = 32\n",
    "hidden_dim = 64\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim, unique_classes, seq_len, embeding_dim, words):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.embeding_dim = embeding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embe = nn.Embedding(len(words), self.embeding_dim)\n",
    "        self.lstm1 = nn.LSTM(self.embeding_dim, self.hidden_dim, batch_first = True)\n",
    "        self.lstm2 = nn.LSTM(self.hidden_dim, self.hidden_dim, batch_first = True)\n",
    "        # self.linear = nn.Linear(hidden_dim * seq_len, unique_classes)\n",
    "        self.linear = nn.Linear(hidden_dim, unique_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _ = x.shape\n",
    "        # lstm_out, _ = self.lstm(x.view(self.seq_len, batch_size, -1))\n",
    "        # outputs = self.linear(lstm_out.reshape(batch_size, -1))\n",
    "        x = self.embe(x)\n",
    "        _, (x, _) = self.lstm1(x) #, (h_0, c_0))\n",
    "        _, (final_hidden_state, _) = self.lstm2(x) #, (h_0, c_0))\n",
    "        outputs = self.linear(final_hidden_state.view(batch_size, -1))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T08:55:58.854733Z",
     "start_time": "2019-12-09T08:55:58.379574Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [64 x 1], m2: [64 x 10] at C:/w/1/s/tmp_conda_3.7_183424/conda/conda-bld/pytorch_1570818936694/work/aten/src\\THC/generic/THCTensorMathBlas.cu:290",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-537f406c3207>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrain_result_all_xd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprovider_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprovider_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprovider_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-4e48e28f8766>\u001b[0m in \u001b[0;36mtrain_result_all_xd\u001b[1;34m(model, optimizer, loss, provider_train, provider_test, provider_validation, device)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mtarget_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-67b98c9bd581>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#, (h_0, c_0))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfinal_hidden_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#, (h_0, c_0))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_hidden_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1368\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [64 x 1], m2: [64 x 10] at C:/w/1/s/tmp_conda_3.7_183424/conda/conda-bld/pytorch_1570818936694/work/aten/src\\THC/generic/THCTensorMathBlas.cu:290"
     ]
    }
   ],
   "source": [
    "unique_classes = 10\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = LSTM(64, 10, 20, 700, words).to(device)\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=1e-2)\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits\n",
    "\n",
    "train_result_all_xd(model, optimizer, loss, provider_train, provider_test, provider_val, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T08:49:45.516436Z",
     "start_time": "2019-12-09T08:49:45.441003Z"
    }
   },
   "outputs": [],
   "source": [
    "def open_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        pickle_data = pickle.load(f)\n",
    "    return pickle_data\n",
    "train = list(open_pickle('./embeddings/words/ONET_train.pickle').values())\n",
    "test = list(open_pickle('./embeddings/words/ONET_test.pickle').values())\n",
    "validation = list(open_pickle('./embeddings/words/ONET_validation.pickle').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T08:49:49.071564Z",
     "start_time": "2019-12-09T08:49:45.771060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28504"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = set()\n",
    "for i in train:\n",
    "    for j in i:\n",
    "            words = words.union(j)\n",
    "for i in test:\n",
    "    for j in i:\n",
    "            words = words.union(j)\n",
    "for i in validation:\n",
    "    for j in i:\n",
    "            words = words.union(j)\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T08:49:49.131399Z",
     "start_time": "2019-12-09T08:49:49.073519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4681, 26669, 15812, ...,  7470,  2620, 10318], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(list(words))\n",
    "le.transform(list(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T08:50:11.087437Z",
     "start_time": "2019-12-09T08:49:49.132361Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./embeddings/words/ONET_train.pickle', 'rb') as f:\n",
    "    pickle_data = pickle.load(f)\n",
    "\n",
    "train_data = {k: list() for k in pickle_data}\n",
    "for label in pickle_data:\n",
    "    for el in pickle_data[label]:\n",
    "        converted = []\n",
    "        converted = le.transform(el)\n",
    "        train_data[label].append(np.array(converted).reshape(len(converted), 1))\n",
    "        \n",
    "data = EmbedDatasetWords(train_data, class_mapping)\n",
    "provider_train = DataLoader(data, batch_size=64, shuffle=True)\n",
    "\n",
    "with open('./embeddings/words/ONET_test.pickle', 'rb') as f:\n",
    "    pickle_data = pickle.load(f)\n",
    "    \n",
    "test_data = {k: list() for k in pickle_data}\n",
    "for label in pickle_data:\n",
    "    for el in pickle_data[label]:\n",
    "        converted = []\n",
    "        converted = le.transform(el)\n",
    "        test_data[label].append(np.array(converted).reshape(len(converted), 1))\n",
    "        \n",
    "data = EmbedDatasetWords(test_data, class_mapping)\n",
    "provider_test = DataLoader(data, batch_size=64, shuffle=True)\n",
    "\n",
    "with open('./embeddings/words/ONET_validation.pickle', 'rb') as f:\n",
    "    pickle_data = pickle.load(f)\n",
    "    \n",
    "val_data = {k: list() for k in pickle_data}\n",
    "for label in pickle_data:\n",
    "    for el in pickle_data[label]:\n",
    "        converted = []\n",
    "        converted = le.transform(el)\n",
    "        val_data[label].append(np.array(converted).reshape(len(converted), 1))\n",
    "        \n",
    "data = EmbedDatasetWords(val_data, class_mapping)\n",
    "provider_val = DataLoader(data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T08:51:59.169245Z",
     "start_time": "2019-12-09T08:50:11.088203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch:   1 | Time:   4.68s | Balanced Acc:  0.10 | Prec:  0.56 | Recall:  0.73 | F1:  0.62 | Matthews:  0.07 |\n",
      "| Epoch:   2 | Time:   4.66s | Balanced Acc:  0.13 | Prec:  0.60 | Recall:  0.71 | F1:  0.63 | Matthews:  0.08 |\n",
      "| Epoch:   3 | Time:   4.71s | Balanced Acc:  0.14 | Prec:  0.59 | Recall:  0.68 | F1:  0.62 | Matthews:  0.08 |\n",
      "| Epoch:   4 | Time:   4.74s | Balanced Acc:  0.15 | Prec:  0.59 | Recall:  0.66 | F1:  0.62 | Matthews:  0.07 |\n",
      "| Epoch:   5 | Time:   4.65s | Balanced Acc:  0.15 | Prec:  0.59 | Recall:  0.67 | F1:  0.62 | Matthews:  0.08 |\n",
      "| Epoch:   6 | Time:   4.69s | Balanced Acc:  0.16 | Prec:  0.59 | Recall:  0.66 | F1:  0.62 | Matthews:  0.08 |\n",
      "| Epoch:   7 | Time:   4.80s | Balanced Acc:  0.15 | Prec:  0.59 | Recall:  0.66 | F1:  0.62 | Matthews:  0.07 |\n",
      "| Epoch:   8 | Time:   5.31s | Balanced Acc:  0.15 | Prec:  0.59 | Recall:  0.67 | F1:  0.62 | Matthews:  0.08 |\n",
      "| Epoch:   9 | Time:   9.46s | Balanced Acc:  0.15 | Prec:  0.60 | Recall:  0.68 | F1:  0.62 | Matthews:  0.08 |\n",
      "| Epoch:  10 | Time:   6.59s | Balanced Acc:  0.15 | Prec:  0.60 | Recall:  0.68 | F1:  0.63 | Matthews:  0.10 |\n",
      "| Epoch:  11 | Time:   5.79s | Balanced Acc:  0.15 | Prec:  0.59 | Recall:  0.67 | F1:  0.62 | Matthews:  0.09 |\n",
      "| Epoch:  12 | Time:   5.79s | Balanced Acc:  0.15 | Prec:  0.59 | Recall:  0.69 | F1:  0.63 | Matthews:  0.09 |\n",
      "| Epoch:  13 | Time:   5.47s | Balanced Acc:  0.16 | Prec:  0.59 | Recall:  0.68 | F1:  0.63 | Matthews:  0.11 |\n",
      "| Epoch:  14 | Time:   6.18s | Balanced Acc:  0.16 | Prec:  0.59 | Recall:  0.68 | F1:  0.62 | Matthews:  0.08 |\n",
      "| Epoch:  15 | Time:   4.92s | Balanced Acc:  0.16 | Prec:  0.60 | Recall:  0.67 | F1:  0.62 | Matthews:  0.08 |\n",
      "| Epoch:  16 | Time:   4.81s | Balanced Acc:  0.15 | Prec:  0.61 | Recall:  0.69 | F1:  0.63 | Matthews:  0.10 |\n",
      "| Epoch:  17 | Time:   4.81s | Balanced Acc:  0.15 | Prec:  0.59 | Recall:  0.68 | F1:  0.63 | Matthews:  0.09 |\n",
      "| Epoch:  18 | Time:   5.05s | Balanced Acc:  0.15 | Prec:  0.59 | Recall:  0.64 | F1:  0.61 | Matthews:  0.08 |\n",
      "| Epoch:  19 | Time:   5.57s | Balanced Acc:  0.11 | Prec:  0.59 | Recall:  0.61 | F1:  0.60 | Matthews:  0.07 |\n",
      "| Epoch:  20 | Time:   4.94s | Balanced Acc:  0.14 | Prec:  0.59 | Recall:  0.64 | F1:  0.61 | Matthews:  0.09 |\n",
      "| TEST SET | Balanced Acc:  0.16 | Prec:  0.55 | Recall:  0.60 | F1:  0.56 | Matthews:  0.14 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1855: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\tomas\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1634172634940347,\n",
       " 0.54901270055837,\n",
       " 0.6014975041597338,\n",
       " 0.5648433538078744,\n",
       " 0.13605801501937742)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_classes = 10\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = LSTM(64, 10, 20, 700, words).to(device)\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=1e-2)\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits\n",
    "\n",
    "train_result_all_xd(model, optimizer, loss, provider_train, provider_test, provider_val, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
